# ðŸ“‹ Info Retrieval - Cheat Sheet

**KEY TERMS**

* **Vector**: A mathematical representation of a document as a set of weighted terms
* **Term Frequency (tf)**: The frequency of a term in a document
* **Inverse Document Frequency (idf)**: A measure of how rare a term is across all documents
* **Cosine Similarity**: A measure of similarity between two vectors, calculated as the cosine of the angle between them

**ALGORITHMS**

* **Vector Space Model (VSM)**: For information retrieval tasks, such as searching and ranking documents
* **Preprocessing**: To improve efficiency in searching and ranking documents by pre-computing the "preferred list" for each term

**FORMULAS**

* **tf-idf weight**: tf \* idf = (1 + log tf) \* log(N/df)
	+ tf: term frequency
	+ idf: inverse document frequency
	+ N: total number of documents
	+ df: document frequency of a term
* **Cosine Similarity**: cosSim(d, q) = (d \* q) / (|d| \* |q|)
	+ d: document vector
	+ q: query vector

**MUST-KNOW FACTS**

* Collection size: 10,000 documents
* Vocabulary size: 7 terms
* Document frequency:
	+ A(50)
	+ B(1300)
	+ C(250)

**QUICK REFERENCE**

* VSM algorithm steps:
	1. Convert documents to weighted term vectors
	2. Convert queries to weighted term vectors
	3. Compute cosine similarity between query and each document vector
	4. Rank documents by decreasing score
* Preprocessing steps:
	1. Pre-compute, for each term, its k nearest documents (treat each term as a 1-term query)
	2. Store the "preferred list" for each term